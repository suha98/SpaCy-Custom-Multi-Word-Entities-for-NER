{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "from datetime import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "import regex as re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.pipeline import EntityRuler\n",
    "import re\n",
    "from spacy.tokens import Span\n",
    "from spacy.util import filter_spans\n",
    "from spacy.training.example import Example\n",
    "from spacy.language import Language\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tahia.Tabassum\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\util.py:865: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "tokenizer = nlp.tokenizer\n",
    "all_stopwords = nlp.Defaults.stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_cats.csv')\n",
    "equip = pd.read_csv('Equipment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning up the dataframe\n",
    "\n",
    "def clean_notes(data, col_name):\n",
    "    data[col_name] = data[col_name].str.replace('lc', 'lamp column')\n",
    "    data[col_name] = data[col_name].str.replace('l/c', 'lamp column')\n",
    "    data[col_name] = data[col_name].str.replace('sugg', 'suggested')\n",
    "    data[col_name] = data[col_name].str.replace('rreturn', 'return')\n",
    "    data[col_name] = data[col_name].str.replace('o/s', 'outside')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_notes(df, 'job_notes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if a string matches a regex pattern\n",
    "\n",
    "def regex_checker(text, pattern):\n",
    "    matches = re.finditer(pattern, text)\n",
    "    for match in matches:\n",
    "        print (match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json file\n",
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to a json file\n",
    "def save_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms the data into a json structure\n",
    "#The counter counts the number of unique entities in the data\n",
    "\n",
    "def structure_data(text, doc_param, counter):\n",
    "    results=[]\n",
    "    entities = []\n",
    "    ignore = ['GPE', 'DATE', 'ADDRESS', 'ORG', 'PERSON', 'FAC', 'TIME', 'NORP', 'MONEY', 'LOC']\n",
    "    for ent in doc_param.ents:\n",
    "        if ent.label_ not in ignore:\n",
    "            entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "            counter[ent.label_] = counter.get(ent.label_, 0) + 1\n",
    "    \n",
    "    if len(entities) > 0:\n",
    "        results = [text, {\"entities\": entities}]\n",
    "    else:\n",
    "        results = None\n",
    "    \n",
    "    return (results), counter\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.entity_removal(doc)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to remove the QUANTITY entity from the list of default entities\n",
    "\n",
    "@Language.component(\"entity_removal\")\n",
    "def entity_removal(doc):\n",
    "    ents = list(doc.ents)\n",
    "    for ent in ents:\n",
    "        print(ent.label_)\n",
    "        if ent.label_=='QUANTITY':\n",
    "            ents.remove(ent)\n",
    "    ents = tuple(ents)\n",
    "    doc.ents = ents\n",
    "    return(doc)\n",
    "Language.component(\"entity_removal\", func=entity_removal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "\n",
    "def train_spacy(data, iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\", last=True)\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            \n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        nlp.add_pipe(\"entity_removal\", before=\"ner\")\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print (\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                # Update the model\n",
    "                nlp.update([example], losses=losses, drop=0.2, sgd = optimizer)\n",
    "            print (losses)\n",
    "    return (nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a csv of keywords needed to be labelled as the 'NEW EQUIPMENT' entity if found in the data\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before = \"ner\")\n",
    "for i in range(len(equip)):    \n",
    "    ruler.add_patterns([{\"label\": \"NEW EQUIPMENT\", \"pattern\": equip.iloc[i,0]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patterns to identify new entities\n",
    "patterns =  [{\"label\": \"ADDRESS\", \"pattern\": [\" ?outside \\d+ ?\", \" ?\\d{1,3} [A-Za-z]+ road\\.?\",\n",
    "                                             \" ?\\d{1,3} [A-Za-z]+ rd\\.?\",\" ?\\d{1,3} [A-Za-z]+ hill\\.?\",\n",
    "                                              \" ?\\d{1,3} [A-Za-z]+ Hill\\.?\", \" ?\\d{1,3} st\\.? [A-Za-z]+\",\n",
    "                                              \" ?\\d{1,3} saint\\.? [A-Za-z]+\", \"\\s\\d{1}[A-Za-z]{2}\\s|\\s\\d{1}[A-Za-z]{2}$|^\\d{1}[A-Za-z]{2}\\s\"]},\n",
    "            {\"label\": \"COLUMN MEASUREMENT\", \"pattern\": [\"(^ ?\\d+(\\.)?\\d*n?m (column)?)|(^ ?\\d+(\\.)?\\d*N?M (column)?)\",\n",
    "                                                       \"(^ ?\\d+(\\.)?\\d* (column)? ?)|(^ ?\\d+(\\.)?\\d* meter ?[A-Za-z]*)\"]},\n",
    "            {\"label\": \"PHONE NUMBER\", \"pattern\": [\" ?\\d{3} ?\\d{7,8}\"]},\n",
    "            {\"label\": \"DAY\", \"pattern\": [\" ?(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday|monday|tuesday|wednesday|thursday|friday|saturday|sunday) ?\"]},\n",
    "            {\"label\": \"NEW EQUIPMENT\", \"pattern\": [\"supply and install \\w* columns? ?\"]},\n",
    "            {\"label\": \"TEMPERATURE\", \"pattern\": [\"( ?\\d{1,4}k ?)|( ?\\d{1,4}K ?)\"]},\n",
    "            {\"label\": \"POWER\", \"pattern\": [\"( ?\\d{1,4}w)|( ?\\d{1,4}W)\"]},\n",
    "            {\"label\": \"LANTERN FEATURE\", \"pattern\": [\" ?\\d{1,3} led lantern ?\"]},\n",
    "            {\"label\": \"REFERENCE\", \"pattern\": [\"(lamp)? ?column \\d{1,4} ?\"]},\n",
    "            {\"label\": \"JOB NUMBER\", \"pattern\": [\"( ?job( number)?| ?quote( number)?| ?quotation( number)?) ?\\d+ ?\"]},\n",
    "            {\"label\": \"CUSTOM_QUANTITY\", \"pattern\": [\" ?remove (one|two|three|four|five|six|seven|eight|nine) [a-z]+ ?[a-z]* ?\",\n",
    "                                              \" ?replace (one|two|three|four|five|six|seven|eight|nine) [a-z]+\\b ?[a-z]*\\b ?\",\n",
    "                                             \" ?[a-z]* ?[a-z]* damaged x\\d{1,3} ?[a-z]* ?\",\n",
    "                                              \" ?x ?\\d{1,4} ?[a-z]* ?\",\n",
    "                                              \" ?x?\\d{1,4} illuminated (sign)? posts? ?\",\n",
    "                                              \" ?[a-z]* ?[a-z]* \\d* x ?\\d{1,3} ?[a-z]* ?\",\n",
    "                                              \" ?supply (one|two|three|four|five|six|seven|eight|nine) [a-z]+ ?[a-z]* ?\",\n",
    "                                              \" ?\\d{1,4} ?[a-z]+ to upgrade$ ?\"                 \n",
    "                                             ]}\n",
    "            \n",
    "     ]\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'ADDRESS',\n",
       " 'pattern': [' ?outside \\\\d+ ?',\n",
       "  ' ?\\\\d{1,3} [A-Za-z]+ road\\\\.?',\n",
       "  ' ?\\\\d{1,3} [A-Za-z]+ rd\\\\.?',\n",
       "  ' ?\\\\d{1,3} [A-Za-z]+ hill\\\\.?',\n",
       "  ' ?\\\\d{1,3} [A-Za-z]+ Hill\\\\.?',\n",
       "  ' ?\\\\d{1,3} st\\\\.? [A-Za-z]+',\n",
       "  ' ?\\\\d{1,3} saint\\\\.? [A-Za-z]+',\n",
       "  '\\\\s\\\\d{1}[A-Za-z]{2}\\\\s|\\\\s\\\\d{1}[A-Za-z]{2}$|^\\\\d{1}[A-Za-z]{2}\\\\s']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_text = []\n",
    "train = []\n",
    "counter = {}\n",
    "\n",
    "entity_json=[]\n",
    "#list of new entities\n",
    "#nlp.add_pipe(\"entity_removal\", before=\"ner\")\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    doc = nlp(train_df.iloc[i, 3])\n",
    "    \n",
    "    ents = list(doc.ents)\n",
    "    for ent in ents:\n",
    "        if ent.label_=='QUANTITY':\n",
    "            ents.remove(ent)\n",
    "    ents = tuple(ents)\n",
    "    doc.ents = ents\n",
    "    \n",
    "    original_ents = list(doc.ents)\n",
    "\n",
    "    new_ents = []\n",
    "\n",
    "    #Identifying new multiple-word entities using regex patterns\n",
    "    for m in range(len(patterns)):\n",
    "        for n in range(len(patterns[m]['pattern'])):\n",
    "            for match in re.finditer(patterns[m]['pattern'][n], doc.text):\n",
    "                start, end = match.span()\n",
    "                span = doc.char_span(start, end, alignment_mode = 'expand')\n",
    "                if span is not None:\n",
    "                    #appending start char, end char, and text of entity\n",
    "                    new_ents.append((span.start, span.end, span.text))\n",
    "                    #print(span.text, patterns[m]['label'])\n",
    "                \n",
    "        for ent in new_ents:\n",
    "            start, end, name = ent\n",
    "            per_ent = Span(doc, start, end, label=patterns[m]['label'])\n",
    "            original_ents.append(per_ent)    \n",
    "   \n",
    "    #prioritizing the matches        \n",
    "    filtered = filter_spans(original_ents)\n",
    "    #print(filtered)\n",
    "    #updating entities\n",
    "    doc.ents = filtered \n",
    "    small_entities =[]\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entity_text.append((ent.text, ent.label_))\n",
    "    x = [train_df.iloc[i,3], {'entities': entity_text}]\n",
    "    if len(entity_text)>0:\n",
    "        entity_json.append(x)\n",
    "    \n",
    "    results, counter = structure_data(train_df.iloc[i, 3], doc, counter)\n",
    "    if results != None:\n",
    "        train.append(results)\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print (len(train))\n",
    "save_data(\"training_data.json\", train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"labels_training_data.json\", entity_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 1647.1958266718552}\n",
      "Starting iteration 1\n",
      "{'ner': 676.78769595937}\n",
      "Starting iteration 2\n",
      "{'ner': 519.2003353200348}\n",
      "Starting iteration 3\n",
      "{'ner': 438.5287167724247}\n",
      "Starting iteration 4\n",
      "{'ner': 360.2200547630951}\n",
      "Starting iteration 5\n",
      "{'ner': 351.8670820593295}\n",
      "Starting iteration 6\n",
      "{'ner': 300.7903429463749}\n",
      "Starting iteration 7\n",
      "{'ner': 352.4327928516401}\n",
      "Starting iteration 8\n",
      "{'ner': 259.4880218898682}\n",
      "Starting iteration 9\n",
      "{'ner': 267.04299725110644}\n",
      "Starting iteration 10\n",
      "{'ner': 251.27171776720024}\n",
      "Starting iteration 11\n",
      "{'ner': 214.40712465301996}\n",
      "Starting iteration 12\n",
      "{'ner': 181.4726970639915}\n",
      "Starting iteration 13\n",
      "{'ner': 203.97288683493335}\n",
      "Starting iteration 14\n",
      "{'ner': 172.49316962409452}\n",
      "Starting iteration 15\n",
      "{'ner': 154.37017681258186}\n",
      "Starting iteration 16\n",
      "{'ner': 166.73938198865687}\n",
      "Starting iteration 17\n",
      "{'ner': 171.53055568468102}\n",
      "Starting iteration 18\n",
      "{'ner': 123.63836893908147}\n",
      "Starting iteration 19\n",
      "{'ner': 192.15249339831195}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = load_data(\"training_data.json\")\n",
    "TRAIN_DATA = trim_entity_spans(TRAIN_DATA)\n",
    "random.shuffle(TRAIN_DATA)\n",
    "nlp = train_spacy(TRAIN_DATA, 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the test set from the trained model\n",
    "small_entities =[]\n",
    "for i in range(len(test_df)):\n",
    "    entities = []\n",
    "    doc = nlp(test_df.iloc[i,3])\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    results = [test_df.iloc[i,3], {'entities': entities}]\n",
    "    if len(entities)>0:\n",
    "        small_entities.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"test_results.json\", small_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suppy operative for filming on 4th march 2021 btwn 4pm, and midnight   confirmation of work completed', {'entities': [[31, 34, 'ORDINAL']]}]\n"
     ]
    }
   ],
   "source": [
    "docs = load_data(\"real_test_data.json\")\n",
    "print (docs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import offsets_to_biluo_tags\n",
    "def get_cleaned_label(label: str):\n",
    "    if \"-\" in label:\n",
    "        return label.split(\"-\")[1]\n",
    "    else:\n",
    "        return label\n",
    "    \n",
    "def create_total_target_vector(docs):\n",
    "    target_vector = []\n",
    "    for doc in docs:\n",
    "        print (doc)\n",
    "        new = nlp.make_doc(doc[0])\n",
    "        entities = doc[1][\"entities\"]\n",
    "        bilou_entities = offsets_to_biluo_tags(new, entities)\n",
    "        final = []\n",
    "        for item in bilou_entities:\n",
    "            final.append(get_cleaned_label(item))\n",
    "        target_vector.extend(final)\n",
    "    return target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_vector(text):\n",
    "    return [get_cleaned_label(prediction) for prediction in get_all_ner_predictions(text)]\n",
    "\n",
    "def create_total_prediction_vector(docs: list):\n",
    "    prediction_vector = []\n",
    "    for doc in docs:\n",
    "        prediction_vector.extend(create_prediction_vector(doc[0]))\n",
    "    return prediction_vector\n",
    "\n",
    "def get_all_ner_predictions(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "    bilou_entities = offsets_to_biluo_tags(doc, entities)\n",
    "    return bilou_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_labels():\n",
    "    labels = list(nlp.get_pipe(\"ner\").labels)\n",
    "    labels.append(\"O\")\n",
    "    return sorted(labels)\n",
    "def get_dataset_labels():\n",
    "    return sorted(set(create_total_target_vector(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "def generate_confusion_matrix(docs): \n",
    "    classes = sorted(set(create_total_target_vector(docs)))\n",
    "    y_true = create_total_target_vector(docs)\n",
    "    y_pred = create_total_prediction_vector(docs)\n",
    "    print('YTRUE')\n",
    "    print (y_true)\n",
    "    print('YPRED')\n",
    "    print (y_pred)\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "    return confusion_matrix(y_true, y_pred, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def plot_confusion_matrix(docs, classes, normalize=False, cmap=pyplot.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "   \n",
    "    title = 'Confusion Matrix, for SpaCy NER'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = generate_confusion_matrix(docs)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "    fig, ax = pyplot.subplots()\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=numpy.arange(cm.shape[1]),\n",
    "           yticks=numpy.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    pyplot.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "         for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return cm, ax, pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(docs,classes=get_dataset_labels(),normalize=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
